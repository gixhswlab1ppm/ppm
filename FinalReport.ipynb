{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalReport.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "tG2L14M4bBEb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Homework 5: Project Report\n",
        "This homework is very similar to homework 5, except now you've hopefully finished your project! You should fill in each of the sections below based on your results. Note that each section has changed from homework 5, so don't just copy paste, the questions are different!\n",
        "\n",
        "Only one member of the group should submit this assignment, however, please provide the names of each member of the group here:\n",
        "\n",
        "**Group Members:**\n",
        "*   Jason Cui\n",
        "*   James Gan\n",
        "*   Shine Lin"
      ]
    },
    {
      "metadata": {
        "id": "YM0M2oRXbBEd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 1: Problem Description\n",
        "* Describe the functionality of your finished product. Try to explain it as if you were writing for a potential customor.\n",
        "\n",
        "The Smart Ping Pong Paddle is able to use real-time swing detection, swing spectrum extraction, ball-hit detection and ball-hit quality scoring. These analytical features give you a basic understanding of your skill level and improvement for ping pong. We offer some functions on a stable release, with experimental functions for reference that my have some bugs. Furthermore, our experimental feature allows you to know the quality of your swings without the need to actually serve and hit balls, making it easier to practice without an expensive needing an expensive robot to launch balls at you. This feature allows you to practice your swing as you begin your ping pong journey, saving you from the laborious work of repeatedly hitting and collecting balls- you don't even need a ping pong table!\n",
        "    \n",
        "* Did anything about your project goals change from the beginning of the quarter? What caused the change?\n",
        "\n",
        "We originally planned to classify between good/bad players, to classify different swings, and to classify additional variables around what makes a player good. However, it was difficult to attain well-labeled data for this (we had various forms of noise from our sensors that would change whenever we modified our device), and our project ran out of budget well in advance of being able to test out additional methods to get this sort of data without an additional device (such as a sepreate camera). As a result, we changed out project goal from being an over-arching device capable of improving any factor of a player's behavior, to simply providing a device that would allow beginners to improve and track their ping pong skills.\n",
        "\n",
        "* If you had more time, what would you do differently?\n",
        "\n",
        "If we had more time, would separate our process into additional, smaller steps, to allow us to collect data and train it with waterfall methodology, so that we could ensure a hardware freeze before working on the complex software aspects. Furthermore, that would also allow us to more appropriately distribute work between team members. In this way, we would hope to be able to develop numerous hardware prototypes and develop models for each of them to determine which setups worked best for our end results.\n",
        "  \n",
        "\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "jQosW1n5bBEe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2: Dataset Description\n",
        "* How did you collect your dataset?\n",
        "\n",
        "We collected our data in three different ways:\n",
        "\n",
        "1. <b>Feasibility Test</b> Initially, we attached a cell phone to a ping pong paddle and used an app to collect acceleration and gyroscope data. The user being monitored swung the paddle repeatedly, as if he were serving a ball.\n",
        "  \n",
        "2. <b>FT - Advanced</b> As we started to develop machine learning models and other algorithms, we continued to use this device configuration but monitored additional users and had them either swing the paddle or to walk around intermittently.\n",
        "  \n",
        "3. <b>Milestone 1-3</b> Once we had our hardware device created, we began to use it to collect swing-related data from an Inertial Measurement Unit (MPU-6050) and to collect hit-related data using several piezoelectric discs. We asked several testers to repeatedly serve an actual ball, allowing natural practice (such as picking up balls, walking around, and taking breaks).\n",
        "\n",
        "For our third way, we had various hardware iterations that affected the scaling and noise for each dataset collected.\n",
        "  \n",
        "* What features did your dataset have?\n",
        "\n",
        "Our dataset had three primary feature categories:\n",
        "\n",
        "**Raw input features**: IMU acceleration/IMU angular velocity ($F^6$), piezoelectric disk reading which indicates vibration strength ($N^3$)\n",
        "\n",
        "**Manually labelled features**: Player Skill/Quality ($B$), Player ID ($N$)\n",
        "\n",
        "**Engineering features**: Ball Hitting Event ($N$), Ball Hitting Temporal Dispersity (BHTD)/Ball Hitting Spatial Dispersity (BHSD)/Ball Hitting Strength (BHS) ($F^3\\times N$), Top-K Signal In Frequency Domain ($F\\times N$), Hit Location.\n",
        "\n",
        "\n",
        "* What were the labels?\n",
        "\n",
        "Some preprocessed features themselves are used as labels, such as the piezometer readings; other labels are manually annotated, such as player skill. Some tasks do not have labels.\n",
        "    \n",
        "For swing and hit detection, there were no labels. However, technically speaking, to fine-tune and verify the algorithms, we did manually visualize these features and counted swings and hits. The extra information generated by manually counting swings and hits is implicitly encoded into our model, thus could be treated as labels.\n",
        "    \n",
        "For hit quality prediction, labels are the aforementioned float-type engineering features including BHTD, BHSD, and BHS.\n",
        "\n",
        "* How many samples did you collect?\n",
        "\n",
        "   * <b>Feasibility Test</b> At least 5 valid files (tests) were collected, each consisting 20+ swings and hits.\n",
        "   \n",
        "   * <b>Milestone 1-3</b> At least 13 valid files (tests) were collected. Around 10 of them consist of 120+ swings and hits, and another 2 of them consists of 0 swings or hits for zero offset deteciton purposes; 6 of them (with valid swings and hits) are well annotated with exact number of swings and hits, and the names of the testers to distinguish different swing/hit patterns among different testers. \n",
        "\n",
        "\n",
        "* What is your final opinion of your dataset? If you could do it again, what would you change?\n",
        "\n",
        "    * Our dataset is enough for the basic model to learn, having 20 groups of training data from 20 different people, each at least swing the paddle 20 times. Though the total number of train dataset can be more, we collect as many features as we can in the process, which is advided from our class instructor. \n",
        "    * We don't think we can do anything different of what we have done when we can do it again.except one thing. The only thing we can do make sure whether the data from sensors is easy to collect and process. As we said, we suffer from piezos data collecting, so we can leave this part and focus on the data processing from IMU, and save our time to further step in machine learning. "
      ]
    },
    {
      "metadata": {
        "id": "yfWM6KXJbBEf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 3: Model Design\n",
        "* What type of architecture did you use? Was it the same as you expected? If not, why?\n",
        "  * We used dynamic single layer RNN model with zero state value to train our dataset. We have only one layer in our RNN model with 32 hidden units. It didn't fully meet our expectation but is still useful. We can decrease our regrassion loss, shown in the below graphs, however, the testing accuracy can be higher, I believe we can do more things with our 70% testing accuracy model. One of the unexpected thing will be explained more in the below paragraph.\n",
        "  **TODO** Same w/ HW4 for the \"experimental feature\"\n",
        "  \n",
        "  * Hit Location Detection\n",
        "    \n",
        "    We initially tried to solve the intersection of three circles to obtain the location of where the ball hits the paddle. These circles have the same location with the deployed three piezo discs, and their diameters are linear to each reading of the sensors. It did not work too well because 1) a single intersection usually does not exist, 2) strong hits close to one sensor could result in a far-away location that is way off the paddle.\n",
        "    \n",
        "    We re-implemented the hit location detection algorithm by introducing \"weighted centroid\" which calculates the centroid of the 3 piezo discs with weights linear to the sensor readings. This worked well (theoretically) if the hit is inside the triangle formed by the 3 discs; otherwise, it is not able to locate.\n",
        "    \n",
        "    We eventually dropped this feature due to the fact that sensor readings themselves are unreliable.\n",
        "    \n",
        "  * Swing Detection/Counting\n",
        "  \n",
        "    We counted the number of swings in a given series of data (length unlimited if thresholds are given; otherwise a minimum length is required to ensure algorithm quality) by 1) finding the local maximas along each dimension of the input features  2) auto-clustering these maximas with a given maxium clustering temporal window along each dimension, and 3) taking the median of number of clusters of all dimensions.\n",
        "    \n",
        "    If a threshold is not given (as is the case when our product \"meets\" a new player for the first time), we require the player to keep swinging for 10+ seconds. After this, our algorithms learns appropriate thresholds for the player by taking 0.6 times the standard deviation along each dimension. This requires no zero-offseting of any dimension.\n",
        "    \n",
        "  * Hit Detection/Counting\n",
        "  \n",
        "    A similar mechanism is used for hit detection except that a hard-coded filter is applied to piezo disc readings before they are fed to auto-clustering steps. The maximum clustering window for hit detection is smaller than that used in swing detection.\n",
        "    \n",
        "  * Swing Spectrum\n",
        "   \n",
        "    Fast Fouirer Transform is used for extracting the spectrum for swings. Some tweaks include: 1) we shifted the data first to align its mean to zero before feeding the data to FFT, 2) we drew a partition window to the temporal data if applicable so that we could handle a mixture of \"swings & walks\" better, 3) we only take some top 10% signals in the frequency domain to generate the spectrum, and 4) we converted frequency domain to period domain so that spectrum has a reasonable \"length\" along the x-axis (noises are usually of randomly-high frequency which have an extremely short period).\n",
        "    \n",
        "  * Hit Quality Prediction/Regression\n",
        "  \n",
        "    Depending on the deployment type of the machine learning task, we need to consider the supported operations and architectures by TF Lite as we design and train the model.\n",
        "\n",
        "    * <b>TF Version</b>\n",
        "\n",
        "      Input -> SimpleRNN -> Dense -> BatchNorm -> Dropout -> BatchNorm -> Dropout -> Dense (Output)\n",
        "\n",
        "    * <b>TF Lite Version</b>\n",
        "\n",
        "      Input -> Conv1D -> Flatten -> Dense -> BatchNorm -> Dropout -> Dense -> BatchNorm -> Dropout -> Dense (Output)\n",
        "\n",
        "    Since TF Lite does not support RNN nor ELU activations, the RNN has been replaced by Conv1D and ELU has been replaced by ReLU instead.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* Show the structure of your architecture (graphic here)\n",
        "\n",
        "    For Hit Quality Prediction/Regression Only:\n",
        "\n",
        "    <img src=\"https://i.imgur.com/PnHIH5O.jpg\"></img>\n",
        "    \n",
        "    Total params: 1,360\n",
        "    \n",
        "    Trainable params: 1,312\n",
        "    \n",
        "    Non-trainable params: 48\n",
        "  \n",
        "  \n"
      ]
    },
    {
      "metadata": {
        "id": "h_QtFHmGbBEg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 4: Training\n",
        "* What was your final training and test accuracy? How many epochs did it take to reach that?\n",
        "\n",
        "   Results for the regression after 1024 epochs:\n",
        "   \n",
        "   * Training Set - Error\n",
        "   \n",
        "      err mean: 0.0496, 25-quant: 0.0184, 50-quant: 0.0338, 75-quant: 0.0659\n",
        "      \n",
        "   * Test Set - Error\n",
        "  \n",
        "      err mean: 0.1631, 25-quant: 0.0658, 50-quant: 0.1609, 75-quant: 0.2441\n",
        "  \n",
        "      Note that actual value roughly range from 0-1, while the predicted value exactly range from 0-1.\n",
        "    \n",
        "   * Loss Along Epochs\n",
        "  \n",
        "      <img src=\"https://github.com/gixhswlab1ppm/ppm/blob/master/insights/Figure_34.png?raw=true\"/>\n",
        "  \n",
        "   * Training Set - Error Visualization (order rearranged)\n",
        "  \n",
        "      <img src=\"https://github.com/gixhswlab1ppm/ppm/blob/master/insights/Figure_40.png?raw=true\"/>\n",
        "  \n",
        "   * Test Set - Error Visualization 1 (order rearranged)\n",
        "  \n",
        "      <img src=\"https://github.com/gixhswlab1ppm/ppm/blob/master/insights/Figure_42.png?raw=true\"/>\n",
        "  \n",
        "    * Test Set - Error Visualization 2 (order rearranged)\n",
        "   \n",
        "      <img src=\"https://github.com/gixhswlab1ppm/ppm/blob/master/insights/Figure_41.png?raw=true\"/>\n",
        "  \n",
        "  \n",
        "* Did you encounter any unexpected issues during training?\n",
        "\n",
        "  * We were suffering from parameter tuning process in our training model. For example, when the dropout values are not zero, the model learnt less and is easy to overfit. So our current solution is set the dropout values to zero, keeping evry neuron in our model for better training result. We think the reason of this is that our dataset is not enough for the model to actually implementing dropout method. If we have more data, we may not suffer from this issue in the future."
      ]
    },
    {
      "metadata": {
        "id": "G8JUmDWtbBEh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 5: Deployment\n",
        "\n",
        "**TODO**\n",
        "\n",
        "* Describe the method used to fun your model, how did it fit into the rest of your system?\n",
        "\n",
        "  *  \n",
        "* Are you happy with how the project turned out? Why or why not?\n",
        "  * We think the result now is good enough that our model is learning \"something\" from our dataset and the regression loss can decrease. This means that we can classify players into two at least classes, good player and bad player, and meet our initial goal set in the beginning of the lab: helping beginners to learn how to play ping pong. From this prespective, we are happy with the result. But we also believe that we can let our model do more tasks when it comes to teaching the beginners. For example, adding the tracking lines for the players' swinging feature for the beginners to compare their tracking lines to those who play really well."
      ]
    }
  ]
}